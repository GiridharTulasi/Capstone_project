{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "id": "ZbIWGJWBl6PL",
        "outputId": "d89910f2-7ebd-4296-ee3e-cc914589022c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-27.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Downloading Faker-27.0.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-27.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "fake=Faker()\n",
        "import pandas as pd\n",
        "from random import randint, uniform, choice"
      ],
      "metadata": {
        "id": "dmqsOMAVl6Sg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countries = [\n",
        "    \"China\", \"United States\", \"United Kingdom\", \"Japan\", \"South Korea\",\n",
        "    \"Germany\", \"France\", \"Canada\", \"Australia\", \"India\",\n",
        "    \"Brazil\", \"Russia\", \"Italy\", \"Spain\", \"Mexico\",\n",
        "    \"Netherlands\", \"Sweden\", \"Switzerland\", \"Turkey\", \"Indonesia\",\n",
        "    \"Saudi Arabia\", \"Argentina\", \"South Africa\", \"Poland\", \"Belgium\",\n",
        "    \"Thailand\", \"Malaysia\", \"Philippines\", \"Vietnam\", \"Singapore\",\n",
        "    \"New Zealand\", \"Norway\", \"Denmark\", \"Finland\", \"Ireland\",\n",
        "    \"Portugal\", \"Greece\", \"Austria\", \"Israel\", \"Chile\",\n",
        "    \"Colombia\", \"Peru\", \"Czech Republic\", \"Hungary\", \"Romania\",\n",
        "    \"Ukraine\", \"Egypt\", \"United Arab Emirates\", \"Qatar\", \"Kuwait\"\n",
        "]\n",
        "\n",
        "#clothing\n",
        "def input_clothing_data(x):\n",
        "    # List of product names for the clothing category\n",
        "    product_names = [\"T-shirts\", \"Jeans\", \"Dresses\", \"Skirts\", \"Blouses\",\n",
        "                     \"Sweaters\", \"Hoodies\", \"Jackets\", \"Coats\", \"Shorts\",\n",
        "                      \"Leggings\", \"Suits\", \"Blazers\", \"Cardigans\", \"Tank tops\",\n",
        "                     \"Polo shirts\", \"Sweatpants\", \"Joggers\", \"Overalls\", \"Jumpsuits\",\n",
        "                     \"Rompers\", \"Swimwear\", \"Socks\", \"Scarves\",\n",
        "                     \"Hats\", \"Gloves\", \"Belts\", \"Activewear\", \"Loungewear\",\n",
        "                     \"Nightwear\", \"Formal wear\",\"Casual wear\"]\n",
        "\n",
        "    # List of brands for the clothing category\n",
        "    brands = [\"Zara\", \"H&M\", \"Uniqlo\", \"ASOS\", \"Mango\", \"Forever 21\", \"Urban Outfitters\",\n",
        "              \"Boohoo\", \"Shein\", \"Revolve\", \"Nordstrom\", \"Saks Fifth Avenue\",\n",
        "              \"Shopbop\", \"Everlane\", \"Reformation\", \"Bandier\", \"T.J. Maxx\",\n",
        "              \"Eloquii\", \"Farfetch\", \"Anthropologie\", \"Free People\", \"Madewell\",\n",
        "              \"J.Crew\", \"Net-a-Porter\", \"MatchesFashion\", \"SSENSE\", \"Mytheresa\",\n",
        "              \"COS\", \"Topshop\", \"Levi's\", \"Nike\", \"Adidas\", \"Puma\", \"Gucci\", \"Prada\",\n",
        "              \"Burberry\", \"Balenciaga\", \"Saint Laurent\", \"Versace\", \"Tommy Hilfiger\"]\n",
        "\n",
        "    # pandas dataframe\n",
        "    data = pd.DataFrame()\n",
        "    for i in range(0, x):\n",
        "        data.loc[i, 'product_name'] = choice(product_names)\n",
        "        data.loc[i, 'Price'] = round(uniform(100.0, 5000.0), 2)\n",
        "        data.loc[i, 'Description'] = fake.sentence()\n",
        "        data.loc[i, 'Category'] = 'clothing'\n",
        "        data.loc[i, 'StockQuantity'] = randint(1, 100)\n",
        "        data.loc[i, 'Brand'] = choice(brands)\n",
        "        data.loc[i, 'Rating'] = round(uniform(1.0, 5.0), 1)\n",
        "        data.loc[i, 'Warehouse'] = choice(countries)\n",
        "    return data\n",
        "\n",
        "def input_footwear_data(x):\n",
        "    # List of product names for the footwear category\n",
        "    product_names = [\"Sneakers\", \"Running Shoes\", \"Loafers\", \"Oxfords\", \"Derby Shoes\",\n",
        "                     \"Brogues\", \"Monk Straps\", \"Chelsea Boots\", \"Chukka Boots\", \"Desert Boots\",\n",
        "                      \"Hiking Boots\", \"Work Boots\", \"Combat Boots\", \"Cowboy Boots\",\n",
        "                     \"Rain Boots\", \"Snow Boots\", \"Sandals\", \"Flip Flops\", \"Slides\", \"Espadrilles\",\n",
        "                      \"Boat Shoes\", \"Moccasins\", \"Ballet Flats\", \"Mary Janes\", \"Wedges\",\n",
        "                     \"Stilettos\", \"Pumps\", \"Kitten Heels\", \"Block Heels\", \"Platform Shoes\",\n",
        "                      \"Clogs\", \"Mules\", \"Ankle Boots\", \"Knee-High Boots\", \"Thigh-High Boots\",\n",
        "                     \"Dress Shoes\", \"Casual Shoes\", \"Athletic Shoes\", \"Dance Shoes\", \"Skate Shoes\"]\n",
        "\n",
        "    # List of brands for the footwear category\n",
        "    brands = [\"Nike\", \"Adidas\", \"Puma\", \"Reebok\", \"New Balance\", \"Asics\", \"Under Armour\",\n",
        "              \"Skechers\", \"Vans\", \"Converse\",\"Timberland\", \"Dr. Martens\", \"Birkenstock\",\n",
        "              \"Clarks\", \"Crocs\", \"UGG\", \"Steve Madden\", \"Aldo\", \"Cole Haan\", \"ECCO\",\n",
        "              \"Merrell\", \"Salomon\", \"Hoka One One\", \"Brooks\", \"Saucony\", \"Mizuno\",\n",
        "              \"Fila\", \"Keds\", \"Toms\", \"Sperry\", \"Teva\", \"Keen\", \"Chaco\", \"Hunter\",\n",
        "              \"Sam Edelman\", \"Stuart Weitzman\", \"Jimmy Choo\", \"Manolo Blahnik\",\n",
        "              \"Christian Louboutin\", \"Gucci\"]\n",
        "\n",
        "    # pandas dataframe\n",
        "    data = pd.DataFrame()\n",
        "    for i in range(0, x):\n",
        "        data.loc[i, 'product_name'] = choice(product_names)\n",
        "        data.loc[i, 'Price'] = round(uniform(100.0, 5000.0), 2)\n",
        "        data.loc[i, 'Description'] = fake.sentence()\n",
        "        data.loc[i, 'Category'] = 'footwear'\n",
        "        data.loc[i, 'StockQuantity'] = randint(1, 100)\n",
        "        data.loc[i, 'Brand'] = choice(brands)\n",
        "        data.loc[i, 'Rating'] = round(uniform(1.0, 5.0), 1)\n",
        "        data.loc[i, 'Warehouse'] = choice(countries)\n",
        "    return data\n",
        "\n",
        "#Generate data\n",
        "clothing_data = input_clothing_data(1500)\n",
        "footwear_data = input_footwear_data(1500)\n",
        "\n",
        "#combine dataframes\n",
        "combined_data_aks = pd.concat([clothing_data,footwear_data], ignore_index=True, axis=0)\n",
        "\n",
        "#convert combined dataframe to csv file\n",
        "combined_data_aks.to_csv('aks_df.csv', index=False)"
      ],
      "metadata": {
        "id": "TGgQL9QimSkV"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Books\n",
        "def input_books_data(x):\n",
        "    # List of book categories\n",
        "    book_categories = [\n",
        "    \"Fantasy\", \"Science Fiction\", \"Mystery\", \"Horror\", \"Historical Fiction\", \"Women’s Fiction\",\n",
        "    \"Literary Fiction\", \"Magic Realism\", \"Graphic Novel\", \"Short Story\", \"Young Adult\", \"New Adult\",\n",
        "    \"Dystopian\", \"Action & Adventure\", \"Thriller & Suspense\", \"Romance\", \"Children’s\", \"Contemporary Fiction\",\n",
        "    \"Biography\", \"Self-Help\", \"History\", \"Memoir & Autobiography\", \"Food & Drink\", \"Art & Photography\", \"Travel\"\n",
        "    ]\n",
        "\n",
        "    # List of book brands\n",
        "    book_brands = [\n",
        "    \"Penguin Random House\", \"HarperCollins\", \"Simon & Schuster\", \"Hachette Livre\", \"Macmillan Publishers\",\n",
        "    \"Scholastic\", \"Pearson\", \"Wiley\", \"Oxford University Press\", \"Cambridge University Press\",\n",
        "    \"Bloomsbury\", \"Harlequin\", \"Pan Macmillan\", \"DK\", \"Faber & Faber\",\n",
        "    \"Cengage Learning\", \"Springer\", \"McGraw-Hill Education\", \"SAGE Publications\", \"Johns Hopkins University Press\",\n",
        "    \"MIT Press\", \"University of Chicago Press\", \"Routledge\", \"Thames & Hudson\", \"Chronicle Books\",\n",
        "    \"Workman Publishing\", \"Andrews McMeel Publishing\", \"Abrams Books\", \"Sterling Publishing\", \"Sourcebooks\"\n",
        "]\n",
        "\n",
        "    data = pd.DataFrame()\n",
        "    for i in range(0, x):\n",
        "        data.loc[i, 'product_name'] = choice(book_categories)\n",
        "        data.loc[i, 'Price'] = round(uniform(100.0, 4000.0), 2)\n",
        "        data.loc[i, 'Description'] = fake.sentence()\n",
        "        data.loc[i, 'Category'] = 'Books'\n",
        "        data.loc[i, 'StockQuantity'] = randint(1, 100)\n",
        "        data.loc[i, 'Brand'] = fake.company()\n",
        "        data.loc[i, 'Rating'] = round(uniform(1.0, 5.0), 1)\n",
        "        data.loc[i, 'Warehouse'] = choice(countries)\n",
        "    return data\n",
        "\n",
        "#Accessories\n",
        "def input_accessories_data(x):\n",
        "    #List of accessories types\n",
        "    accessories = ['Belt','Earring','Glasses','Glove','Handbag','Hat','Helmet',\n",
        "                   'Necktie','Perfume','Ring','Sash','Sunglasses','Umbrella',\n",
        "                   'Watch','Anklets','Bangles and Bracelets','Brooches and Pins',\n",
        "                   'Cuff Links and Studs','Hair Accessories','Handkerchiefs and Pocket Squares',\n",
        "                   'Luggage','Necklaces and Pendants','Wallets']\n",
        "\n",
        "    #List of accessories brands\n",
        "    brands = ['Gucci','Fossil', 'Prada','Kate Spade','Tory Burch','Bvlgari','Cartier',\n",
        "              'Swarovski','Ray-Ban','Oakley', 'Louis Vuitton', 'Chanel','Michael Kors',\n",
        "              'Coach', 'Hermes', 'Fendi', 'Balenciaga', 'Dior', 'Versace', 'Burberry']\n",
        "\n",
        "    data = pd.DataFrame()\n",
        "    for i in range(0, x):\n",
        "        data.loc[i, 'product_name'] = choice(accessories)\n",
        "        data.loc[i, 'Price'] = round(uniform(100.0, 10000.0), 2)\n",
        "        data.loc[i, 'Description'] = fake.sentence()\n",
        "        data.loc[i, 'Category'] = 'Accessories'\n",
        "        data.loc[i, 'StockQuantity'] = randint(1, 100)\n",
        "        data.loc[i, 'Brand'] = choice(brands)\n",
        "        data.loc[i, 'Rating'] = round(uniform(1.0, 5.0), 1)\n",
        "        data.loc[i, 'Warehouse'] = choice(countries)\n",
        "    return data\n",
        "\n",
        "# Generate data\n",
        "books_data = input_books_data(1500)\n",
        "accessories_data = input_accessories_data(1500)\n",
        "\n",
        "# Combine dataframes\n",
        "combined_data_van = pd.concat([books_data, accessories_data], ignore_index=True)\n",
        "\n",
        "#convert combined dataframe to csv file\n",
        "combined_data_van.to_csv('van_df.csv', index=False)"
      ],
      "metadata": {
        "id": "uFIF1Vtew3Vv"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aks_van = pd.concat([combined_data_aks,combined_data_van], ignore_index=True, axis=0)\n",
        "aks_van.to_csv('aks_van.csv', index=False)"
      ],
      "metadata": {
        "id": "NoSE6uj6ycg_"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of toy names for the product_name column\n",
        "def input_toy_data(x):\n",
        "    # pandas dataframe\n",
        "    toy_names = [\n",
        "        \"Lego\", \"Barbie Doll\", \"Teddy Bear\", \"Rubik's Cube\", \"Hot Wheels\", \"Action Figure\",\n",
        "        \"Puzzle\", \"Board Game\", \"Card Game\", \"Robot Toy\", \"Stuffed Animal\", \"Building Blocks\",\n",
        "        \"Remote Control Car\", \"Dollhouse\", \"Play-Doh\", \"Yo-Yo\", \"Kite\", \"Toy Train\", \"Marbles\",\n",
        "        \"Toy Kitchen Set\", \"Toy Tool Set\", \"Toy Drum Set\", \"Toy Guitar\", \"Toy Piano\", \"Toy Soldier\",\n",
        "        \"Toy Dinosaur\", \"Toy Car\", \"Toy Plane\", \"Toy Boat\", \"Toy Helicopter\"\n",
        "    ]\n",
        "    # List of toy brands\n",
        "    toy_brands = [\n",
        "        \"Lego\", \"Mattel\", \"Hasbro\", \"Fisher-Price\", \"Hot Wheels\", \"Barbie\", \"Nerf\", \"Play-Doh\",\n",
        "        \"Melissa & Doug\", \"VTech\", \"LeapFrog\", \"Little Tikes\", \"Mega Bloks\", \"Tonka\", \"Crayola\",\n",
        "        \"Disney\", \"Nickelodeon\", \"Marvel\", \"DC Comics\", \"Transformers\", \"Star Wars\", \"My Little Pony\",\n",
        "        \"Paw Patrol\", \"Thomas & Friends\", \"Peppa Pig\", \"Playmobil\", \"Schleich\", \"Brio\", \"Chicco\",\n",
        "        \"Fisher-Price\"\n",
        "    ]\n",
        "    data = pd.DataFrame()\n",
        "    for i in range(0, x):\n",
        "        data.loc[i, 'product_name'] = choice(toy_names)\n",
        "        data.loc[i, 'Price'] = round(uniform(5.0, 500.0), 2)\n",
        "        data.loc[i, 'Description'] = fake.sentence()\n",
        "        data.loc[i, 'Category'] = 'Toys'\n",
        "        data.loc[i, 'StockQuantity'] = randint(1, 100)\n",
        "        data.loc[i, 'Brand'] = choice(toy_brands)\n",
        "        data.loc[i, 'Rating'] = round(uniform(1.0, 5.0), 1)\n",
        "        data.loc[i, 'Warehouse'] = choice(countries)\n",
        "    return data\n",
        "# Example usage\n",
        "df = input_toy_data(1500)\n",
        "#display(df)\n",
        "\n",
        "def input_electronic_data(x):\n",
        "    # pandas dataframe\n",
        "    # List of product names for the electronics category\n",
        "    product_names = [\n",
        "        \"Smartphones\", \"Tablets\", \"Laptops\", \"Smartwatches\", \"E-readers\",\n",
        "        \"Televisions\", \"Streaming Devices\", \"Gaming Consoles\", \"Sound Systems\", \"Blu-ray/DVD Players\",\n",
        "        \"Refrigerators\", \"Microwaves\", \"Washing Machines\", \"Air Conditioners\", \"Vacuum Cleaners\",\n",
        "        \"Electric Shavers\", \"Hair Dryers\", \"Electric Toothbrushes\", \"Fitness Trackers\",\n",
        "        \"Printers\", \"Scanners\", \"Monitors\", \"Keyboards and Mice\",\n",
        "        \"Smart Speakers\", \"Smart Lights\", \"Smart Thermostats\", \"Security Cameras\",\n",
        "        \"Digital Cameras\", \"Portable Chargers\", \"Bluetooth Headphones/Earbuds\", \"Wearable Fitness Devices\"\n",
        "    ]\n",
        "    # List of electronic brands\n",
        "    electronic_brands = [\n",
        "        \"Apple\", \"Samsung\", \"Sony\", \"LG\", \"Dell\", \"HP\", \"Lenovo\", \"Asus\", \"Microsoft\", \"Acer\",\n",
        "        \"Panasonic\", \"Philips\", \"Bose\", \"JBL\", \"Canon\", \"Nikon\", \"GoPro\", \"Fitbit\", \"Garmin\",\n",
        "        \"Xiaomi\", \"Huawei\", \"OnePlus\", \"Oppo\", \"Vivo\", \"Realme\", \"Amazon\", \"Google\", \"Roku\",\n",
        "        \"Nintendo\", \"PlayStation\", \"Xbox\", \"Dyson\", \"Whirlpool\", \"Bosch\", \"Siemens\", \"Toshiba\",\n",
        "        \"Sharp\", \"Sennheiser\", \"Anker\", \"Logitech\"\n",
        "    ]\n",
        "    data = pd.DataFrame()\n",
        "    for i in range(0, x):\n",
        "        data.loc[i, 'product_name'] = choice(product_names)\n",
        "        data.loc[i, 'Price'] = round(uniform(500.0, 150000.0), 2)\n",
        "        data.loc[i, 'Description'] = fake.sentence()\n",
        "        data.loc[i, 'Category'] = 'Electronics'\n",
        "        data.loc[i, 'StockQuantity'] = randint(1, 100)\n",
        "        data.loc[i, 'Brand'] = choice(electronic_brands)\n",
        "        data.loc[i, 'Rating'] = round(uniform(1.0, 5.0), 1)\n",
        "        data.loc[i, 'Warehouse'] = choice(countries)\n",
        "    return data\n",
        "\n",
        "# Generate data\n",
        "toy_data = input_toy_data(1500)\n",
        "electronic_data = input_electronic_data(1500)\n",
        "\n",
        "# Combine dataframes\n",
        "combined_data_1 = pd.concat([toy_data, electronic_data], ignore_index=True, axis=0)\n",
        "\n",
        "#convert combined dataframe to csv file\n",
        "combined_data_1.to_csv('Giri_df.csv', index=False)\n",
        "\n",
        "def input_cosmetics_data(x):\n",
        "    # List of product names for the cosmetics category\n",
        "    product_names = ['lipstick', 'foundation', 'primer' , 'toner' , 'eyeshadow palette' , 'eyebrow palette','mirror',\n",
        "                     'setting spray' ,'moisturizer' , 'concealer', 'eyeliner', 'mascara', 'brushes', 'lipliner', 'lipgloss', 'comb',\n",
        "                     'highlighter', 'blush','body lotion','bronzer','eye cream','hand cream','Lip Balm', 'Lip Gloss', 'Lip Scrub',\n",
        "                     'Eyebrow Powder', 'Eyebrow Gel', 'Eyebrow Pomade', 'Eyebrow Tint', 'Eyelash Curler', 'False Eyelashes', 'Eyelash Glue',\n",
        "                     'Eyelash Primer', 'Eyelash Serum', 'Eyeshadow Primer', 'Eye Makeup Remover', 'Eye Cream', 'Eye Serum', 'Eye Mask',\n",
        "                     'Under Eye Concealer', 'Eye Brightener', 'Eye Shadow Palette', 'Eyeliner Pencil', 'Liquid Eyeliner', 'Gel Eyeliner',\n",
        "                     'Mascara Primer', 'Waterproof Mascara', 'Volumizing Mascara', 'Lengthening Mascara', 'Curling Mascara', 'Eyebrow Stencil',\n",
        "                     'Eyebrow Scissors', 'Eyebrow Brush', 'Eyebrow Comb', 'Eyebrow Highlighter', 'Eyebrow Growth Serum', 'Eyelash Extensions',\n",
        "                     'Eyelash Tint', 'Eye Drops', 'Eye Makeup Brushes', 'Eye Makeup Setting Spray','Lip Mask', 'Lip Oil', 'Lip Stain',\n",
        "                     'Lip Liner', 'Lip Plumper', 'Lip Tint', 'Lip Butter', 'Lip Sleeping Mask', 'Lip Treatment', 'Lip Sunscreen', 'Lip Primer',\n",
        "                     'Lip Exfoliator', 'Lip Moisturizer', 'Lip Volumizer', 'Lip Enhancer', 'Lip Color Corrector', 'Lip Repair',\n",
        "                     'Lip Revitalizer', 'Lip Brightener', 'Lip Smoother', 'Lip Softener', 'Lip Conditioner', 'Lip Protector', 'Lip Shield',\n",
        "                     'Lip Nourisher', 'Lip Hydrator', 'Lip Rejuvenator', 'Lip Detox', 'Lip Cleanser', 'Lip Polish', 'Lip Perfector',\n",
        "                     'Lip Booster', 'Lip Renewal', 'Lip Revitalizing Mask', 'Lip Sleeping Balm', 'Lip Plumping Gloss', 'Lip Tinted Balm']\n",
        "\n",
        "    # List of brands for the cosmetics category\n",
        "    brands = [\"L’Oréal\", \"Estée Lauder\", \"MAC Cosmetics\", \"Maybelline\", \"Clinique\",\n",
        "          \"NARS\", \"Lancôme\", \"Revlon\", \"Urban Decay\", \"Bobbi Brown\", \"Chanel\",\n",
        "          \"Dior\", \"Yves Saint Laurent\", \"Shiseido\", \"Benefit Cosmetics\", \"Too Faced\",\n",
        "          \"Tarte\", \"Smashbox\", \"Fenty Beauty\", \"Huda Beauty\", \"Anastasia Beverly Hills\",\n",
        "          \"Glossier\", \"Pat McGrath Labs\", \"Charlotte Tilbury\", \"Kiehl’s\", \"The Body Shop\",\n",
        "          \"NYX Professional Makeup\", \"IT Cosmetics\", \"Hourglass\", \"Laura Mercier\",\n",
        "          \"CoverGirl\", \"E.l.f. Cosmetics\", \"BareMinerals\", \"Morphe\", \"ColourPop\",\n",
        "          \"Milani\", \"Burt’s Bees\", \"Drunk Elephant\", \"Origins\", \"Pixi Beauty\"]\n",
        "\n",
        "    # pandas dataframe\n",
        "    data = pd.DataFrame()\n",
        "    for i in range(0, x):\n",
        "        data.loc[i, 'product_name'] = choice(product_names)\n",
        "        data.loc[i, 'Price'] = round(uniform(100.0, 5000.0), 2)\n",
        "        data.loc[i, 'Description'] = fake.sentence()\n",
        "        data.loc[i, 'Category'] = 'cosmetics'\n",
        "        data.loc[i, 'StockQuantity'] = randint(1, 100)\n",
        "        data.loc[i, 'Brand'] = choice(brands)\n",
        "        data.loc[i, 'Rating'] = round(uniform(1.0, 5.0), 1)\n",
        "        data.loc[i, 'Warehouse'] = choice(countries)\n",
        "    return data\n",
        "\n",
        "def input_furniture_data(x):\n",
        "    # List of product names for the Furniture category\n",
        "    furniture_products = ['Sofa', 'Couch', 'Armchair', 'Recliner', 'Loveseat',\n",
        "                         'Sectional Sofa', 'Futon', 'Chaise Lounge', 'Ottoman',\n",
        "                         'Coffee Table', 'End Table', 'Console Table', 'Side Table',\n",
        "                         'Dining Table', 'Kitchen Table', 'Bar Table', 'Counter Stool',\n",
        "                         'Dining Chair', 'Desk', 'Office Chair', 'Bookcase',\n",
        "                         'Bookshelf', 'TV Stand', 'Entertainment Center', 'Bed Frame',\n",
        "                         'Mattress', 'Nightstand', 'Dresser', 'Chest of Drawers',\n",
        "                         'Wardrobe', 'Armoire', 'Vanity', 'Bench', 'Stool',\n",
        "                         'Accent Chair']\n",
        "\n",
        "    # List of brands for the Furniture category\n",
        "    furniture_brands = [\"Ashley Furniture\", \"IKEA\", \"Williams-Sonoma\", \"Restoration Hardware\", \"La-Z-Boy\", \"Ethan Allen\", \"Bassett Furniture\", \"Room & Board\", \"Crate & Barrel\", \"West Elm\", \"Pottery Barn\", \"Bernhardt Furniture\", \"Hooker Furniture\", \"Lexington Home Brands\", \"Stanley Furniture\", \"Kincaid Furniture\", \"Thomasville Furniture\", \"Broyhill Furniture\", \"Lane Furniture\", \"Flexsteel Industries\", \"American Leather\", \"Mitchell Gold + Bob Williams\", \"Stickley Furniture\", \"Hickory Chair\", \"Henredon Furniture\", \"Drexel Heritage\", \"Century Furniture\", \"Baker Furniture\", \"Karastan Rugs\", \"Mohawk Industries\", \"Shaw Industries\", \"Interface\", \"Milliken & Company\", \"Tarkett\", \"Mannington Mills\"]\n",
        "\n",
        "    # pandas dataframe\n",
        "    data = pd.DataFrame()\n",
        "    for i in range(0, x):\n",
        "        data.loc[i, 'product_name'] = choice(furniture_products)\n",
        "        data.loc[i, 'Price'] = round(uniform(10.0, 1000.0), 2)\n",
        "        data.loc[i, 'Description'] = fake.sentence()\n",
        "        data.loc[i, 'Category'] = 'Furniture'\n",
        "        data.loc[i, 'StockQuantity'] = randint(1, 100)\n",
        "        data.loc[i, 'Brand'] = choice(furniture_brands)\n",
        "        data.loc[i, 'Rating'] = round(uniform(1.0, 5.0), 1)\n",
        "        data.loc[i, 'Warehouse'] = choice(countries)\n",
        "    return data\n",
        "\n",
        "#generte data\n",
        "cosmetics_data = input_cosmetics_data(1500)\n",
        "furniture_data = input_furniture_data(1500)\n",
        "\n",
        "#combine data\n",
        "combined_data_2 = pd.concat([cosmetics_data, furniture_data], ignore_index=True, axis=0)\n",
        "\n",
        "#print combinational data\n",
        "# input_cosmetics_data(10)\n",
        "# input_furniture_data(10)\n",
        "combined_data_2.to_csv('poojitha.csv',index=False)\n",
        "\n",
        "giri_pooji = pd.concat([combined_data_1,combined_data_2], ignore_index=True, axis=0)\n",
        "# input_electronic_data(20)\n",
        "# input_toy_data(20)\n",
        "giri_pooji.to_csv('Giri_pooji.csv', index=False)"
      ],
      "metadata": {
        "id": "T_HYv2kJy-b5"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = pd.concat([giri_pooji,aks_van], ignore_index=True, axis=0)\n",
        "final_data.to_csv('final_data.csv', index=False)"
      ],
      "metadata": {
        "id": "7xvqLuky5l2g"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r2bgnJKl7mfE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}